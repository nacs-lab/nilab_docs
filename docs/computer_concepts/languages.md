# Compiled Code vs. Interpreted Code

It is worth having clear in your mind the differences between two different kinds of program execution. We can think of a program as a set of instructions that manipulate data (in the broadest sense of these words). This manipulation of data can result in displaying videos on your computer or performing complicated physics calculations. Generally speaking, programs can be either **compiled** or **interpreted**. 

An **interpreted** program is one where lines of code are executed one by one in sequence. An interpreter is responsible for reading a line of code and then executing what it says. Python is probably the most famous example of an interpreted language (though to be fair, I believe Python does have some degree of compiling for the experts in the crowd). They offer incredible flexibility, natively supporting interactive notebooks. They allow for quickly testing pieces of code, and direct access to all intermediate states and stored variables. Typing of variables tends to be dynamic and memory is also dynamically allocated, taken when needed. It is safe to say that interpreted languages like Python are the most user friendly, usually allowing for easy and intuitive setup and debugging. 

A **compiled** program is one where ultimately lines of code are executed one by one (as all programs are), but they are not *necessarily* the exact lines you've written. In a compiled programs, the instructions (code) you write are looked at as a whole and then compiled into a standalone program. Why would one want to do such a thing? What advantages does this bring to the table?

- **Compiled code runs faster**: In general, compiled code runs faster! This is because compiled code can be *optimized*. By knowing all of the code that should be run in the program, compilers use this information to make optimization decisions. For example, if you have code that reads 
```
    a = 1
    a = a + 1
```
In compiled code, we'd likely find that `a` was never 1! It was probably optimized to just take the value 2. Good compilers will try to do as much work as possible ahead of time, and deduce as much as possible from your code to make it efficient. In an interpreted language, since it is unknown what will happen after a given line of execution, the `a = 1` needs to be executed faithfully.

- **Errors are detected earlier in compiled code**: In interpreted code, errors appear when the line in which the error is located is *run*. Suppose you are running a calculation, but a typo is present at the end when the data is saved. In this case, you need to complete the long calculation before you even realize the typo and can lose a lot of time! This is where I always suggest that when using interpreted/script based codes, before running long calculations, try to run a shorter one just to ensure that there is no error after all the hard work is completed! In compiled code, typos do not make it to the program, since the code cannot compile if it doesn't recognize a variable name, for instance. Another somewhat annoying situation is when you have a branch in the code. The error may exist only in one of the branches, so if all your code utilizes the other one, this error may remain hidden. Once again, in compiled code, one needs to contend with such an error to even compile the program.

- **Seemingly non-repeatable behavior is more likely in interpreted code**: One of the simplest, yet true, assumptions of computer programming is that if you run the exact same code multiple times, you should get the exact result every time. After all, as students of physics, this fact should not surprise us! However, based on how strict one is, this principle may be seemingly false. Of course, if we establish the exact same initial conditions down to the atomic level on your computer, then we really ought to expect the same result each time (let's not worry about quantum measurement... or deeper questions about whether physics is deterministic). However, in practical matters, some behavior can actually be *non-deterministic* (at least from the programmer's perspective). When multiple threads are running on a computer, based on the timing relationships of when threads are run (and especially if they share memory resources), different behavior can arise, depending on the *order* in which the threads access the memory. Good multithreaded programming should eliminate such non-deterministic behavior, but nonetheless, this serves as an example of when we might expect non-repeatable behavior. The situation is even worse for interpreted code. In interpreted code (say code that you're running in an interactive notebook such as Jupyter), this can arise quite often. The initial conditions are harder to track. Suppose the user has run the cells in a different order, or for debugging purposes, one quickly defines a variable but then deletes the code to clean up. These are all actions that have consequences on the workspace when another cell block is run. These are considerations that require more special attention when using interpreted code. In compiled code, the program is run fresh every time, and the conditions when a particular block of code executes is more predictable.

- **Dynamic code modifications are tricky in interpreted code**:



